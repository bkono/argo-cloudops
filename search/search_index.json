{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What Is Cello? \u00b6 Cello is a service for running infrastructure as code software tools including CDK, Terraform and Cloud Formation via GitOps. Separate build and deployment Isolate cloud credentials Separate access by project and targets Why Cello? \u00b6 GitOps opperating model Multi cloud support (AWS, GCP, etc) Multi framework support (CDK, Terraform, etc) Pluggable components (Workflows, Frameworks, Credentials Providers, etc) Getting Started \u00b6 For set-up information and running your first Workflows, please see our Getting Started guide.","title":"Overview"},{"location":"#what-is-cello","text":"Cello is a service for running infrastructure as code software tools including CDK, Terraform and Cloud Formation via GitOps. Separate build and deployment Isolate cloud credentials Separate access by project and targets","title":"What Is Cello?"},{"location":"#why-cello","text":"GitOps opperating model Multi cloud support (AWS, GCP, etc) Multi framework support (CDK, Terraform, etc) Pluggable components (Workflows, Frameworks, Credentials Providers, etc)","title":"Why Cello?"},{"location":"#getting-started","text":"For set-up information and running your first Workflows, please see our Getting Started guide.","title":"Getting Started"},{"location":"appendix/","text":"Appendix \u00b6 Artifact Passing Between Steps \u00b6 Only necessary if passing artifacts between steps, not required by default. Install Minio for internal K8s artifact storage. Setup Minio for Argo. Ensure sample artifact passing workflow works.","title":"Appendix"},{"location":"appendix/#appendix","text":"","title":"Appendix"},{"location":"appendix/#artifact-passing-between-steps","text":"Only necessary if passing artifacts between steps, not required by default. Install Minio for internal K8s artifact storage. Setup Minio for Argo. Ensure sample artifact passing workflow works.","title":"Artifact Passing Between Steps"},{"location":"architecture/","text":"Definitions \u00b6 Framework defines the cloud configuration management framework (terraform, cdk). Operation is an abstraction of the type of command to execute. Supports sync and diff . Code Archive is a zip file which contains the framework code for the operation. Projects define a logical grouping of targets. Targets are cloud providers (AWS account, etc) affected by an operation. Workflow Template template of steps to be taken when running a frameowrk command (diff or sync). Workflows execution of workflow template. Arguments are passed to the operation. Can be supplied for init and / or execute . Parameters are passed as inputs to the workflow template. Environment Variables are set in the shell before the operation. These will vary based on the workflow. Images are docker images executed by the workflow. Credentials Provider generates short lived credential tokens exchanged for cloud credentials. Token are used to provide access (multiple types exist, see below for details). Access and Tokens \u00b6 All access is via secrets known as a token . There are multiple types of tokens which can be used by Cello. Admin Token Provides access to manage projects and targets (admin tokens do not have the ability to perform operational commands). The admin token has the format PROVIDER:admin:SECRET . The admin token is set as an environment variable which is read by the service at startup. The admin token is passed in the Authorization header to the service. User Tokens Grants access to operational commands (sync, diff, etc) for a given project. User tokens do not have the ability to manage the associated project or targets. User tokens have the format PROVIDER:USER:SECRET . User tokens are passed in the Authorization header to the service. Credential Tokens Are used to obtain target credentials. Credential tokens are short lived and limited use tokens. They are generated and passed to the workflow during an operation. The token is then exchanged (via the credential provider) for target credentials (AWS credentials, etc). Credential tokens have a format based on the provider and should be considered opaque (for example vault s.ABCDEFGHIJKLMNOPQRSTUVWXYZ ). Credentials tokens are passed from the credential provider to the service and then on to the workflow. State \u00b6 All state is stored in the credential provider (Vault) and Argo Workflows. Operations \u00b6 Operations are converted to the equivalent command in the target framework. Terraform Sync : init, apply Diff : init, plan CDK Sync : deploy Diff : diff Additionally you can define your own frameworks in argo-cloudops.yaml . Workflow \u00b6 Cello uses Argo Workflows as its workflow engine. To execute the provided command, an Argo workflow is submitted by the service. Ordinary users should not need to access Argo workflows directly. Workflows are stored as Argo Workflow Templates. Currently there is one generic workflow for all commands which performs one step which executes the image provided with the command, arguments and environment variables. Config \u00b6 The config file contains the commands executed by different frameworks. The example config in argo-cloudops.yaml contains the default commands to run cdk and terraform .","title":"Architecture"},{"location":"architecture/#definitions","text":"Framework defines the cloud configuration management framework (terraform, cdk). Operation is an abstraction of the type of command to execute. Supports sync and diff . Code Archive is a zip file which contains the framework code for the operation. Projects define a logical grouping of targets. Targets are cloud providers (AWS account, etc) affected by an operation. Workflow Template template of steps to be taken when running a frameowrk command (diff or sync). Workflows execution of workflow template. Arguments are passed to the operation. Can be supplied for init and / or execute . Parameters are passed as inputs to the workflow template. Environment Variables are set in the shell before the operation. These will vary based on the workflow. Images are docker images executed by the workflow. Credentials Provider generates short lived credential tokens exchanged for cloud credentials. Token are used to provide access (multiple types exist, see below for details).","title":"Definitions"},{"location":"architecture/#access-and-tokens","text":"All access is via secrets known as a token . There are multiple types of tokens which can be used by Cello. Admin Token Provides access to manage projects and targets (admin tokens do not have the ability to perform operational commands). The admin token has the format PROVIDER:admin:SECRET . The admin token is set as an environment variable which is read by the service at startup. The admin token is passed in the Authorization header to the service. User Tokens Grants access to operational commands (sync, diff, etc) for a given project. User tokens do not have the ability to manage the associated project or targets. User tokens have the format PROVIDER:USER:SECRET . User tokens are passed in the Authorization header to the service. Credential Tokens Are used to obtain target credentials. Credential tokens are short lived and limited use tokens. They are generated and passed to the workflow during an operation. The token is then exchanged (via the credential provider) for target credentials (AWS credentials, etc). Credential tokens have a format based on the provider and should be considered opaque (for example vault s.ABCDEFGHIJKLMNOPQRSTUVWXYZ ). Credentials tokens are passed from the credential provider to the service and then on to the workflow.","title":"Access and Tokens"},{"location":"architecture/#state","text":"All state is stored in the credential provider (Vault) and Argo Workflows.","title":"State"},{"location":"architecture/#operations","text":"Operations are converted to the equivalent command in the target framework. Terraform Sync : init, apply Diff : init, plan CDK Sync : deploy Diff : diff Additionally you can define your own frameworks in argo-cloudops.yaml .","title":"Operations"},{"location":"architecture/#workflow","text":"Cello uses Argo Workflows as its workflow engine. To execute the provided command, an Argo workflow is submitted by the service. Ordinary users should not need to access Argo workflows directly. Workflows are stored as Argo Workflow Templates. Currently there is one generic workflow for all commands which performs one step which executes the image provided with the command, arguments and environment variables.","title":"Workflow"},{"location":"architecture/#config","text":"The config file contains the commands executed by different frameworks. The example config in argo-cloudops.yaml contains the default commands to run cdk and terraform .","title":"Config"},{"location":"faq/","text":"FAQ \u00b6 Cello server returns \"INTERNAL ERROR\" when following logs This happens when a deployment executes for a long time. Just reissue the logs command to retry. Team is tracking an issue to resolve","title":"FAQ"},{"location":"faq/#faq","text":"Cello server returns \"INTERNAL ERROR\" when following logs This happens when a deployment executes for a long time. Just reissue the logs command to retry. Team is tracking an issue to resolve","title":"FAQ"},{"location":"quickstart/","text":"Quickstart \u00b6 Note: this is a quick guide for getting something up and running. This is configured for local setups and not meant to be run in production Pre-reqs \u00b6 The quickstart currently only supports macOS. Clone the Cello GitHub repository . Install Docker Desktop , ensure Kubernetes is running. Install AWS CLI Install Argo CLI brew install argo Install jq for json parsing. Deploy Sample App Locally \u00b6 You will need two windows Vault & Cello Service Client commands, etc Start Vault & Cello Service \u00b6 In window #1 , ensure you have AWS credentials for the target account configured and access to your kubernetes cluster. For the AWS credentials, export the AWS_PROFILE that is to be used. Set ARGO_CLOUDOPS_ADMIN_SECRET env var to abcd1234abcd1234 . export ARGO_CLOUDOPS_ADMIN_SECRET = abcd1234abcd1234 Start the Cello Service (includes workflows, vault, and postgres). Note: this will copy your current AWS credentials to the vault containers. bash scripts/quickstart_run.sh Create Cello Project And Target (One Time Setup) \u00b6 In window #2 , ensure you have the ARGO_CLOUDOPS_ADMIN_SECRET env var set to abcd1234abcd1234 . export ARGO_CLOUDOPS_ADMIN_SECRET = abcd1234abcd1234 Ensure your AWS credentials are set for the target account and create your first project and target. The output contains an export command for the ARGO_CLOUDOPS_USER_TOKEN for the new project. bash scripts/create_project.sh https://github.com/cello-proj/cello.git Run Workflow \u00b6 In window #2 , ensure the ARGO_CLOUDOPS_USER_TOKEN for the project is specified (the output of create_project.sh should have output a bash command to export it). CDK Example # CDK Example CDK_WORKFLOW_NAME = ` bash scripts/run_gitops_example.sh manifests/kube_cdk_manifest.yaml 5b40793bded1030d8a17d6ddd050ee1ef060f8cc ` # Get the status/follow the logs ./quickstart/argo-cloudops get $CDK_WORKFLOW_NAME ./quickstart/argo-cloudops logs -f $CDK_WORKFLOW_NAME TERRAFORM Example # Terraform Example TERRAFORM_WORKFLOW_NAME = ` bash scripts/run_gitops_example.sh manifests/kube_terraform_manifest.yaml 5b40793bded1030d8a17d6ddd050ee1ef060f8cc ` # Get the status/follow the logs ./quickstart/argo-cloudops get $TERRAFORM_WORKFLOW_NAME ./quickstart/argo-cloudops logs -f $TERRAFORM_WORKFLOW_NAME","title":"Quick Start"},{"location":"quickstart/#quickstart","text":"Note: this is a quick guide for getting something up and running. This is configured for local setups and not meant to be run in production","title":"Quickstart"},{"location":"quickstart/#pre-reqs","text":"The quickstart currently only supports macOS. Clone the Cello GitHub repository . Install Docker Desktop , ensure Kubernetes is running. Install AWS CLI Install Argo CLI brew install argo Install jq for json parsing.","title":"Pre-reqs"},{"location":"quickstart/#deploy-sample-app-locally","text":"You will need two windows Vault & Cello Service Client commands, etc","title":"Deploy Sample App Locally"},{"location":"quickstart/#start-vault-cello-service","text":"In window #1 , ensure you have AWS credentials for the target account configured and access to your kubernetes cluster. For the AWS credentials, export the AWS_PROFILE that is to be used. Set ARGO_CLOUDOPS_ADMIN_SECRET env var to abcd1234abcd1234 . export ARGO_CLOUDOPS_ADMIN_SECRET = abcd1234abcd1234 Start the Cello Service (includes workflows, vault, and postgres). Note: this will copy your current AWS credentials to the vault containers. bash scripts/quickstart_run.sh","title":"Start Vault &amp; Cello Service"},{"location":"quickstart/#create-cello-project-and-target-one-time-setup","text":"In window #2 , ensure you have the ARGO_CLOUDOPS_ADMIN_SECRET env var set to abcd1234abcd1234 . export ARGO_CLOUDOPS_ADMIN_SECRET = abcd1234abcd1234 Ensure your AWS credentials are set for the target account and create your first project and target. The output contains an export command for the ARGO_CLOUDOPS_USER_TOKEN for the new project. bash scripts/create_project.sh https://github.com/cello-proj/cello.git","title":"Create Cello Project And Target (One Time Setup)"},{"location":"quickstart/#run-workflow","text":"In window #2 , ensure the ARGO_CLOUDOPS_USER_TOKEN for the project is specified (the output of create_project.sh should have output a bash command to export it). CDK Example # CDK Example CDK_WORKFLOW_NAME = ` bash scripts/run_gitops_example.sh manifests/kube_cdk_manifest.yaml 5b40793bded1030d8a17d6ddd050ee1ef060f8cc ` # Get the status/follow the logs ./quickstart/argo-cloudops get $CDK_WORKFLOW_NAME ./quickstart/argo-cloudops logs -f $CDK_WORKFLOW_NAME TERRAFORM Example # Terraform Example TERRAFORM_WORKFLOW_NAME = ` bash scripts/run_gitops_example.sh manifests/kube_terraform_manifest.yaml 5b40793bded1030d8a17d6ddd050ee1ef060f8cc ` # Get the status/follow the logs ./quickstart/argo-cloudops get $TERRAFORM_WORKFLOW_NAME ./quickstart/argo-cloudops logs -f $TERRAFORM_WORKFLOW_NAME","title":"Run Workflow"},{"location":"roadmap/","text":"Roadmap \u00b6","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"cli/argo-cloudops/","text":"argo-cloudops \u00b6 argo-cloudops is the command line interface to Cello argo-cloudops [command] Options \u00b6 Available Commands: completion generate the autocompletion script for the specified shell diff Diff a project target using a manifest in git exec Executes an operation on a project target using a manifest in git get Gets status of workflow help Help about any command list List workflow executions for a given project and target logs Gets logs from a workflow sync Syncs a project target using a manifest in git version Reports the version workflow Creates a workflow execution with provided arguments Flags: -h, --help help for argo-cloudops SEE ALSO \u00b6 argo-cloudops logs - gets logs from a workflow","title":"argo-cloudops"},{"location":"cli/argo-cloudops/#argo-cloudops","text":"argo-cloudops is the command line interface to Cello argo-cloudops [command]","title":"argo-cloudops"},{"location":"cli/argo-cloudops/#options","text":"Available Commands: completion generate the autocompletion script for the specified shell diff Diff a project target using a manifest in git exec Executes an operation on a project target using a manifest in git get Gets status of workflow help Help about any command list List workflow executions for a given project and target logs Gets logs from a workflow sync Syncs a project target using a manifest in git version Reports the version workflow Creates a workflow execution with provided arguments Flags: -h, --help help for argo-cloudops","title":"Options"},{"location":"cli/argo-cloudops/#see-also","text":"argo-cloudops logs - gets logs from a workflow","title":"SEE ALSO"},{"location":"cli/argo-cloudops_diff/","text":"argo-cloudops diff \u00b6 Diff a project target using a manifest in git argo-cloudops diff [flags] Flags \u00b6 -h, --help help for diff -p, --path string Path to manifest within git repository -n, --project_name string Name of project -s, --sha string Commit sha to use when creating workflow through git -t, --target string Name of target","title":"argo-cloudops diff"},{"location":"cli/argo-cloudops_diff/#argo-cloudops-diff","text":"Diff a project target using a manifest in git argo-cloudops diff [flags]","title":"argo-cloudops diff"},{"location":"cli/argo-cloudops_diff/#flags","text":"-h, --help help for diff -p, --path string Path to manifest within git repository -n, --project_name string Name of project -s, --sha string Commit sha to use when creating workflow through git -t, --target string Name of target","title":"Flags"},{"location":"cli/argo-cloudops_exec/","text":"argo-cloudops exec \u00b6 Executes an operation on a project target using a manifest in git argo-cloudops exec [flags] Flags \u00b6 -h, --help help for exec -p, --path string Path to manifest within git repository -n, --project_name string Name of project -s, --sha string Commit sha to use when creating workflow through git -t, --target string Name of target","title":"Argo cloudops exec"},{"location":"cli/argo-cloudops_exec/#argo-cloudops-exec","text":"Executes an operation on a project target using a manifest in git argo-cloudops exec [flags]","title":"argo-cloudops exec"},{"location":"cli/argo-cloudops_exec/#flags","text":"-h, --help help for exec -p, --path string Path to manifest within git repository -n, --project_name string Name of project -s, --sha string Commit sha to use when creating workflow through git -t, --target string Name of target","title":"Flags"},{"location":"cli/argo-cloudops_get/","text":"argo-cloudops get \u00b6 Gets status of workflow argo-cloudops get [workflow name] [flags] Flags \u00b6 -h, --help help for get","title":"argo-cloudops get"},{"location":"cli/argo-cloudops_get/#argo-cloudops-get","text":"Gets status of workflow argo-cloudops get [workflow name] [flags]","title":"argo-cloudops get"},{"location":"cli/argo-cloudops_get/#flags","text":"-h, --help help for get","title":"Flags"},{"location":"cli/argo-cloudops_list/","text":"argo-cloudops list \u00b6 List workflow executions for a given project and target argo-cloudops list [flags] Flags \u00b6 -h, --help help for list -n, --project_name string Name of project -t, --target_name string Name of target","title":"argo-cloudops list"},{"location":"cli/argo-cloudops_list/#argo-cloudops-list","text":"List workflow executions for a given project and target argo-cloudops list [flags]","title":"argo-cloudops list"},{"location":"cli/argo-cloudops_list/#flags","text":"-h, --help help for list -n, --project_name string Name of project -t, --target_name string Name of target","title":"Flags"},{"location":"cli/argo-cloudops_logs/","text":"argo-cloudops logs \u00b6 Gets logs from a workflow argo-cloudops logs [workflow name] [flags] Flags \u00b6 -f, --follow Follow workflow logs and stream to standard out until workflow is complete -h, --help help for logs","title":"argo-cloudops logs"},{"location":"cli/argo-cloudops_logs/#argo-cloudops-logs","text":"Gets logs from a workflow argo-cloudops logs [workflow name] [flags]","title":"argo-cloudops logs"},{"location":"cli/argo-cloudops_logs/#flags","text":"-f, --follow Follow workflow logs and stream to standard out until workflow is complete -h, --help help for logs","title":"Flags"},{"location":"cli/argo-cloudops_sync/","text":"argo-cloudops sync \u00b6 Syncs a project target using a manifest in git argo-cloudops sync [flags] Flags \u00b6 -h, --help help for sync -p, --path string Path to manifest within git repository -n, --project_name string Name of project -s, --sha string Commit sha to use when creating workflow through git -t, --target string Name of target","title":"argo-cloudops sync"},{"location":"cli/argo-cloudops_sync/#argo-cloudops-sync","text":"Syncs a project target using a manifest in git argo-cloudops sync [flags]","title":"argo-cloudops sync"},{"location":"cli/argo-cloudops_sync/#flags","text":"-h, --help help for sync -p, --path string Path to manifest within git repository -n, --project_name string Name of project -s, --sha string Commit sha to use when creating workflow through git -t, --target string Name of target","title":"Flags"},{"location":"cli/argo-cloudops_workflow/","text":"argo-cloudops workflow \u00b6 Creates a workflow execution with provided arguments argo-cloudops workflow [flags] Flags \u00b6 -a, --arguments string CSV string of equals separated arguments to pass to command (-a Arg1=ValueA,Arg2=ValueB). -e, --environment_variables string CSV string of equals separated environment variable key value pairs (-e Key1=ValueA,Key2=ValueB) -f, --framework string Framework to execute -h, --help help for workflow -p, --parameters string CSV string of equals separated parameters name and value (-p Param1=ValueA,Param2=ValueB). -n, --project_name string Name of project -t, --target string Name of target --type string Workflow type to execute -w, --workflow_template_name string Name of the workflow template","title":"argo-cloudops workflow"},{"location":"cli/argo-cloudops_workflow/#argo-cloudops-workflow","text":"Creates a workflow execution with provided arguments argo-cloudops workflow [flags]","title":"argo-cloudops workflow"},{"location":"cli/argo-cloudops_workflow/#flags","text":"-a, --arguments string CSV string of equals separated arguments to pass to command (-a Arg1=ValueA,Arg2=ValueB). -e, --environment_variables string CSV string of equals separated environment variable key value pairs (-e Key1=ValueA,Key2=ValueB) -f, --framework string Framework to execute -h, --help help for workflow -p, --parameters string CSV string of equals separated parameters name and value (-p Param1=ValueA,Param2=ValueB). -n, --project_name string Name of project -t, --target string Name of target --type string Workflow type to execute -w, --workflow_template_name string Name of the workflow template","title":"Flags"},{"location":"developers/CONTRIBUTING/","text":"Contributing \u00b6 How To Provide Feedback \u00b6 Please raise an issue in Github . Code of Conduct \u00b6 See CNCF Code of Conduct . How To Contribute \u00b6 We're always looking for contributors. Documentation - something missing or unclear? Please submit a pull request! Code contribution - investigate an issue Local Development Environment \u00b6 To run Cello locally for development . Test Policy \u00b6 Changes without unit tests are unlikely to be accepted.","title":"Contributing"},{"location":"developers/CONTRIBUTING/#contributing","text":"","title":"Contributing"},{"location":"developers/CONTRIBUTING/#how-to-provide-feedback","text":"Please raise an issue in Github .","title":"How To Provide Feedback"},{"location":"developers/CONTRIBUTING/#code-of-conduct","text":"See CNCF Code of Conduct .","title":"Code of Conduct"},{"location":"developers/CONTRIBUTING/#how-to-contribute","text":"We're always looking for contributors. Documentation - something missing or unclear? Please submit a pull request! Code contribution - investigate an issue","title":"How To Contribute"},{"location":"developers/CONTRIBUTING/#local-development-environment","text":"To run Cello locally for development .","title":"Local Development Environment"},{"location":"developers/CONTRIBUTING/#test-policy","text":"Changes without unit tests are unlikely to be accepted.","title":"Test Policy"},{"location":"developers/api/","text":"API \u00b6 Create Project \u00b6 POST /projects Request Body { \"name\" : \"project1\" , \"repository\" : \"git@github.com:myorg/myrepo.git\" } Response Body { \"token\": \"abcd-1234\" } Get Project \u00b6 GET /projects/ Response Body { \"name\": \"myproject\" } Delete Project \u00b6 DELETE /projects/ Projects can only be deleted if they have no targets Response Body Create Target \u00b6 POST /projects/ /targets Request Body { \"name\" : \"target1\" , \"type\" : \"aws_account\" , \"properties\" : { \"credential_type\" : \"assumed_role\" , \"policy_arns\" : [ \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" , \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\" , \"arn:aws:iam::aws:policy/AmazonSQSFullAccess\" , \"arn:aws:iam::aws:policy/AWSCloudFormationFullAccess\" ], \"policy_document\" : \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"s3:ListBuckets\\\", \\\"Resource\\\": \\\"*\\\" } ] }\" , \"role_arn\" : \"arn:aws:iam::<ACCOUNT_ID>:role/<ROLE_NAME>\" } } Note: role_arn will be assumed as the target by vault. Vault's IAM credentials must be a principle authorized to assume this role. The policy_arns and policy_document will be applied at role assumption time to scope down permissions. Today only type is only aws_account and credential_type is only assumed role. Response Body {} List Targets \u00b6 GET /projects/ /targets Response Body [ \"target1\" , \"target2\" ] Get Target \u00b6 GET /projects/ /targets/ Response Body { \"name\" : \"target1\" , \"type\" : \"aws_account\" , \"properties\" : { \"credential_type\" : \"assumed_role\" , \"policy_arns\" : [ \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" , \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\" , \"arn:aws:iam::aws:policy/AmazonSQSFullAccess\" , \"arn:aws:iam::aws:policy/AWSCloudFormationFullAccess\" ], \"policy_document\" : \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"s3:ListBuckets\\\", \\\"Resource\\\": \\\"*\\\" } ] }\" , \"role_arn\" : \"arn:aws:iam::123456789012:role/ArgoCloudOpsSampleRole\" } } Update Target \u00b6 PATCH /projects/ /targets/ Request Body { \"properties\" : { \"policy_arns\" : [ \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" , \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\" , \"arn:aws:iam::aws:policy/AmazonSQSFullAccess\" , \"arn:aws:iam::aws:policy/AWSCloudFormationFullAccess\" ], \"policy_document\" : \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"s3:ListBuckets\\\", \\\"Resource\\\": \\\"*\\\" } ] }\" , \"role_arn\" : \"arn:aws:iam::<ACCOUNT_ID>:role/<ROLE_NAME>\" } } Note: Target properties that are provided will be updated with the new values provided. Properties that are not provided in the PATCH request will remain with their current values. credential_type cannot be updated Response Body { \"name\" : \"target1\" , \"type\" : \"aws_account\" , \"properties\" : { \"credential_type\" : \"assumed_role\" , \"policy_arns\" : [ \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" , \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\" , \"arn:aws:iam::aws:policy/AmazonSQSFullAccess\" , \"arn:aws:iam::aws:policy/AWSCloudFormationFullAccess\" ], \"policy_document\" : \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"s3:ListBuckets\\\", \\\"Resource\\\": \\\"*\\\" } ] }\" , \"role_arn\" : \"arn:aws:iam::123456789012:role/ArgoCloudOpsSampleRole\" } } Delete Target \u00b6 DELETE /projects/ /targets/ Response Body Create Workflow \u00b6 POST /workflows Request Body { \"arguments\" : { \"execute\" : [ \"-auto-approve\" , \"-no-color\" ], \"init\" : [ \"-no-color\" ] }, \"environment_variables\" : { \"AWS_REGION\" : \"us-west-2\" , \"CODE_URI\" : \"s3://argo-cloudops-cet-dev/terraform-example.zip\" , \"VAULT_ADDR\" : \"http://docker.for.mac.localhost:8200\" }, \"framework\" : \"terraform\" , \"parameters\" : { \"execute_container_image_uri\" : \"a80addc4/argo-cloudops-terraform:0.14.5\" }, \"project_name\" : \"project1\" , \"target_name\" : \"target1\" , \"type\" : \"sync\" , \"workflow_template_name\" : \"argo-cloudops-single-step-vault-aws\" } Note: Arguments will be concatenated with spaces before appended to the command. Response Body { \"workflow_name\" : \"abcd\" } Perform Target Operations From Git Manifest \u00b6 POST /projects/ /targets/ /operations Request Body { \"sha\" : \"1234abdc5678efgh9012ijkl3456mnop7890qrst\" , \"path\" : \"path/to/manifest.yaml\" } Response Body { \"workflow_name\" : \"abcd\" } Get Workflow \u00b6 GET /workflows/ Response Body { \"name\" : \"workflow1\" , \"status\" : \"failed\" , \"created\" : \"1618515183\" , \"finished\" : \"1618515193\" } Get Workflow Logs \u00b6 GET /workflows/ /logs Response Body { \"logs\" : [ \"Log line 1\" , \"Log line 2\" ] } Get Workflow Logstream \u00b6 GET /workflows/ /logstream Response Body Log line 1 Log line 2 List Project / Target Workflows \u00b6 GET /projects/ /targets/ /workflows Response Body [ { \"name\" : \"workflow1\" , \"status\" : \"failed\" , \"created\" : \"1618515183\" , \"finished\" : \"1618515193\" }, { \"name\" : \"workflow2\" , \"status\" : \"failed\" , \"created\" : \"1618512676\" , \"finished\" : \"1618512686\" } ]","title":"API"},{"location":"developers/api/#api","text":"","title":"API"},{"location":"developers/api/#create-project","text":"POST /projects Request Body { \"name\" : \"project1\" , \"repository\" : \"git@github.com:myorg/myrepo.git\" } Response Body { \"token\": \"abcd-1234\" }","title":"Create Project"},{"location":"developers/api/#get-project","text":"GET /projects/ Response Body { \"name\": \"myproject\" }","title":"Get Project"},{"location":"developers/api/#delete-project","text":"DELETE /projects/ Projects can only be deleted if they have no targets Response Body","title":"Delete Project"},{"location":"developers/api/#create-target","text":"POST /projects/ /targets Request Body { \"name\" : \"target1\" , \"type\" : \"aws_account\" , \"properties\" : { \"credential_type\" : \"assumed_role\" , \"policy_arns\" : [ \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" , \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\" , \"arn:aws:iam::aws:policy/AmazonSQSFullAccess\" , \"arn:aws:iam::aws:policy/AWSCloudFormationFullAccess\" ], \"policy_document\" : \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"s3:ListBuckets\\\", \\\"Resource\\\": \\\"*\\\" } ] }\" , \"role_arn\" : \"arn:aws:iam::<ACCOUNT_ID>:role/<ROLE_NAME>\" } } Note: role_arn will be assumed as the target by vault. Vault's IAM credentials must be a principle authorized to assume this role. The policy_arns and policy_document will be applied at role assumption time to scope down permissions. Today only type is only aws_account and credential_type is only assumed role. Response Body {}","title":"Create Target"},{"location":"developers/api/#list-targets","text":"GET /projects/ /targets Response Body [ \"target1\" , \"target2\" ]","title":"List Targets"},{"location":"developers/api/#get-target","text":"GET /projects/ /targets/ Response Body { \"name\" : \"target1\" , \"type\" : \"aws_account\" , \"properties\" : { \"credential_type\" : \"assumed_role\" , \"policy_arns\" : [ \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" , \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\" , \"arn:aws:iam::aws:policy/AmazonSQSFullAccess\" , \"arn:aws:iam::aws:policy/AWSCloudFormationFullAccess\" ], \"policy_document\" : \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"s3:ListBuckets\\\", \\\"Resource\\\": \\\"*\\\" } ] }\" , \"role_arn\" : \"arn:aws:iam::123456789012:role/ArgoCloudOpsSampleRole\" } }","title":"Get Target"},{"location":"developers/api/#update-target","text":"PATCH /projects/ /targets/ Request Body { \"properties\" : { \"policy_arns\" : [ \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" , \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\" , \"arn:aws:iam::aws:policy/AmazonSQSFullAccess\" , \"arn:aws:iam::aws:policy/AWSCloudFormationFullAccess\" ], \"policy_document\" : \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"s3:ListBuckets\\\", \\\"Resource\\\": \\\"*\\\" } ] }\" , \"role_arn\" : \"arn:aws:iam::<ACCOUNT_ID>:role/<ROLE_NAME>\" } } Note: Target properties that are provided will be updated with the new values provided. Properties that are not provided in the PATCH request will remain with their current values. credential_type cannot be updated Response Body { \"name\" : \"target1\" , \"type\" : \"aws_account\" , \"properties\" : { \"credential_type\" : \"assumed_role\" , \"policy_arns\" : [ \"arn:aws:iam::aws:policy/AmazonS3FullAccess\" , \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\" , \"arn:aws:iam::aws:policy/AmazonSQSFullAccess\" , \"arn:aws:iam::aws:policy/AWSCloudFormationFullAccess\" ], \"policy_document\" : \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"s3:ListBuckets\\\", \\\"Resource\\\": \\\"*\\\" } ] }\" , \"role_arn\" : \"arn:aws:iam::123456789012:role/ArgoCloudOpsSampleRole\" } }","title":"Update Target"},{"location":"developers/api/#delete-target","text":"DELETE /projects/ /targets/ Response Body","title":"Delete Target"},{"location":"developers/api/#create-workflow","text":"POST /workflows Request Body { \"arguments\" : { \"execute\" : [ \"-auto-approve\" , \"-no-color\" ], \"init\" : [ \"-no-color\" ] }, \"environment_variables\" : { \"AWS_REGION\" : \"us-west-2\" , \"CODE_URI\" : \"s3://argo-cloudops-cet-dev/terraform-example.zip\" , \"VAULT_ADDR\" : \"http://docker.for.mac.localhost:8200\" }, \"framework\" : \"terraform\" , \"parameters\" : { \"execute_container_image_uri\" : \"a80addc4/argo-cloudops-terraform:0.14.5\" }, \"project_name\" : \"project1\" , \"target_name\" : \"target1\" , \"type\" : \"sync\" , \"workflow_template_name\" : \"argo-cloudops-single-step-vault-aws\" } Note: Arguments will be concatenated with spaces before appended to the command. Response Body { \"workflow_name\" : \"abcd\" }","title":"Create Workflow"},{"location":"developers/api/#perform-target-operations-from-git-manifest","text":"POST /projects/ /targets/ /operations Request Body { \"sha\" : \"1234abdc5678efgh9012ijkl3456mnop7890qrst\" , \"path\" : \"path/to/manifest.yaml\" } Response Body { \"workflow_name\" : \"abcd\" }","title":"Perform Target Operations From Git Manifest"},{"location":"developers/api/#get-workflow","text":"GET /workflows/ Response Body { \"name\" : \"workflow1\" , \"status\" : \"failed\" , \"created\" : \"1618515183\" , \"finished\" : \"1618515193\" }","title":"Get Workflow"},{"location":"developers/api/#get-workflow-logs","text":"GET /workflows/ /logs Response Body { \"logs\" : [ \"Log line 1\" , \"Log line 2\" ] }","title":"Get Workflow Logs"},{"location":"developers/api/#get-workflow-logstream","text":"GET /workflows/ /logstream Response Body Log line 1 Log line 2","title":"Get Workflow Logstream"},{"location":"developers/api/#list-project-target-workflows","text":"GET /projects/ /targets/ /workflows Response Body [ { \"name\" : \"workflow1\" , \"status\" : \"failed\" , \"created\" : \"1618515183\" , \"finished\" : \"1618515193\" }, { \"name\" : \"workflow2\" , \"status\" : \"failed\" , \"created\" : \"1618512676\" , \"finished\" : \"1618512686\" } ]","title":"List Project / Target Workflows"},{"location":"developers/development-env/","text":"Development Environment setup \u00b6 Pre-reqs \u00b6 The below instructions assume Cello is on your local OSX system with Docker Desktop managing resource in AWS (region us-west-2) with credentials provided by Vault. Install Docker Desktop , ensure kubernetes is running. Install Argo Workflows Install Argo CLI brew install argo Install GoLang brew install golang Install GoLint go get -u golang.org/x/lint/golint and ensure $GOPATH is in your $PATH . Install PostgreSQL brew install postgresql Install Vault for credential generation. Install jq for json parsing. Install npm brew install npm (For CDK). Install terraform . Validate argo workflows is setup and working correctly. \u00b6 Submit Argo Hello World workflow and record the Name from the output. argo submit -n argo https://raw.githubusercontent.com/argoproj/argo-workflows/master/examples/hello-world.yaml Ensure the workflow completes with Status Succeeded . argo get -n argo <UPDATE_WITH_NAME_FROM_ABOVE> |grep Status Deploy Sample App Locally \u00b6 You will need two windows Vault & Cello Service Client commands, etc One Time Setup \u00b6 In window #1 , ensure you have AWS credentials for the target account. Create the IAM role which will be used for the sample project. bash scripts/create_iam_role.sh Create a new postgres database. This can be done using the command: createdb argocloudops Use the createdbtables.sql script to create the relevant tables and create a new user with read/write permissions. This can be done using the command: psql -d argocloudops -f scripts/createdbtables.sql Create the default workflow template in Argo. argo template create -n argo workflows/argo-cloudops-single-step-vault-aws.yaml Start Vault & Cello Service \u00b6 In window #1 first set the ARGO_CLOUDOPS_ADMIN_SECRET to a 16 character string, this will be used to authorize admin commands against the Cello service. export ARGO_CLOUDOPS_ADMIN_SECRET = abcd1234abcd1234 Start the Cello Service (includes vault) make ; make up To run in debug mode set log level DEBUG before running export ARGO_CLOUDOPS_LOG_LEVEL=DEBUG make ; make up Create Cello Project And Target (One Time Setup) \u00b6 In window #2 , ensure you have the ARGO_CLOUDOPS_ADMIN_SECRET env set to the same value used above. Ensure your credentials are set for the target account and create your first project and target. This returns the ARGO_CLOUDOPS_USER_TOKEN for the new project. bash scripts/create_project.sh https://github.com/cello-proj/cello.git Run Workflow \u00b6 Ensure the ARGO_CLOUDOPS_USER_TOKEN for the project is specified CDK Example # CDK Example CDK_WORKFLOW_NAME = ` bash scripts/run_gitops_example.sh manifests/cdk_manifest.yaml 60675a3012c63dd7edc9097654246e48438fa93d dev ` # Get the status / logs ./build/argo-cloudops get $CDK_WORKFLOW_NAME ./build/argo-cloudops logs $CDK_WORKFLOW_NAME TERRAFORM Example # Terraform Example TERRAFORM_WORKFLOW_NAME = ` bash scripts/run_gitops_example.sh manifests/terraform_manifest.yaml 60675a3012c63dd7edc9097654246e48438fa93d dev ` # Get the status / logs ./build/argo-cloudops get $TERRAFORM_WORKFLOW_NAME ./build/argo-cloudops logs $TERRAFORM_WORKFLOW_NAME","title":"Local Development Environment"},{"location":"developers/development-env/#development-environment-setup","text":"","title":"Development Environment setup"},{"location":"developers/development-env/#pre-reqs","text":"The below instructions assume Cello is on your local OSX system with Docker Desktop managing resource in AWS (region us-west-2) with credentials provided by Vault. Install Docker Desktop , ensure kubernetes is running. Install Argo Workflows Install Argo CLI brew install argo Install GoLang brew install golang Install GoLint go get -u golang.org/x/lint/golint and ensure $GOPATH is in your $PATH . Install PostgreSQL brew install postgresql Install Vault for credential generation. Install jq for json parsing. Install npm brew install npm (For CDK). Install terraform .","title":"Pre-reqs"},{"location":"developers/development-env/#validate-argo-workflows-is-setup-and-working-correctly","text":"Submit Argo Hello World workflow and record the Name from the output. argo submit -n argo https://raw.githubusercontent.com/argoproj/argo-workflows/master/examples/hello-world.yaml Ensure the workflow completes with Status Succeeded . argo get -n argo <UPDATE_WITH_NAME_FROM_ABOVE> |grep Status","title":"Validate argo workflows is setup and working correctly."},{"location":"developers/development-env/#deploy-sample-app-locally","text":"You will need two windows Vault & Cello Service Client commands, etc","title":"Deploy Sample App Locally"},{"location":"developers/development-env/#one-time-setup","text":"In window #1 , ensure you have AWS credentials for the target account. Create the IAM role which will be used for the sample project. bash scripts/create_iam_role.sh Create a new postgres database. This can be done using the command: createdb argocloudops Use the createdbtables.sql script to create the relevant tables and create a new user with read/write permissions. This can be done using the command: psql -d argocloudops -f scripts/createdbtables.sql Create the default workflow template in Argo. argo template create -n argo workflows/argo-cloudops-single-step-vault-aws.yaml","title":"One Time Setup"},{"location":"developers/development-env/#start-vault-cello-service","text":"In window #1 first set the ARGO_CLOUDOPS_ADMIN_SECRET to a 16 character string, this will be used to authorize admin commands against the Cello service. export ARGO_CLOUDOPS_ADMIN_SECRET = abcd1234abcd1234 Start the Cello Service (includes vault) make ; make up To run in debug mode set log level DEBUG before running export ARGO_CLOUDOPS_LOG_LEVEL=DEBUG make ; make up","title":"Start Vault &amp; Cello Service"},{"location":"developers/development-env/#create-cello-project-and-target-one-time-setup","text":"In window #2 , ensure you have the ARGO_CLOUDOPS_ADMIN_SECRET env set to the same value used above. Ensure your credentials are set for the target account and create your first project and target. This returns the ARGO_CLOUDOPS_USER_TOKEN for the new project. bash scripts/create_project.sh https://github.com/cello-proj/cello.git","title":"Create Cello Project And Target (One Time Setup)"},{"location":"developers/development-env/#run-workflow","text":"Ensure the ARGO_CLOUDOPS_USER_TOKEN for the project is specified CDK Example # CDK Example CDK_WORKFLOW_NAME = ` bash scripts/run_gitops_example.sh manifests/cdk_manifest.yaml 60675a3012c63dd7edc9097654246e48438fa93d dev ` # Get the status / logs ./build/argo-cloudops get $CDK_WORKFLOW_NAME ./build/argo-cloudops logs $CDK_WORKFLOW_NAME TERRAFORM Example # Terraform Example TERRAFORM_WORKFLOW_NAME = ` bash scripts/run_gitops_example.sh manifests/terraform_manifest.yaml 60675a3012c63dd7edc9097654246e48438fa93d dev ` # Get the status / logs ./build/argo-cloudops get $TERRAFORM_WORKFLOW_NAME ./build/argo-cloudops logs $TERRAFORM_WORKFLOW_NAME","title":"Run Workflow"},{"location":"developers/releasing/","text":"Releasing \u00b6 This project uses GoReleaser and GitHub Actions for releases. You can find the release workflow at ./github/workflows/release.yaml . The release workflow only triggers on tags which start with v (e.g. v0.1.0 ). To create a new release: Ensure the CHANGELOG.md is up to date (bump to the desired version, etc) on main . Locally, tag main with the desired semver version and push the tag up. git tag v0.1.0 && git push --tags The release process should begin. This will build/package artifacts and create a GitHub release with the relevant CHANGELOG.md entries and artifacts attached. If the release process does not find entries for the associated tag, it will pull the entries in the ## [Unreleased] section. You can create a tag for a semver pre-release version, such as: v0.1.0 followed by a hyphen and characters ( v0.1.0-dev1 , v0.1.0-alpha , etc.). This will result in creating a GitHub pre-release. This can be useful for testing without releasing a \"final\" version.","title":"Releasing"},{"location":"developers/releasing/#releasing","text":"This project uses GoReleaser and GitHub Actions for releases. You can find the release workflow at ./github/workflows/release.yaml . The release workflow only triggers on tags which start with v (e.g. v0.1.0 ). To create a new release: Ensure the CHANGELOG.md is up to date (bump to the desired version, etc) on main . Locally, tag main with the desired semver version and push the tag up. git tag v0.1.0 && git push --tags The release process should begin. This will build/package artifacts and create a GitHub release with the relevant CHANGELOG.md entries and artifacts attached. If the release process does not find entries for the associated tag, it will pull the entries in the ## [Unreleased] section. You can create a tag for a semver pre-release version, such as: v0.1.0 followed by a hyphen and characters ( v0.1.0-dev1 , v0.1.0-alpha , etc.). This will result in creating a GitHub pre-release. This can be useful for testing without releasing a \"final\" version.","title":"Releasing"},{"location":"developers/static-code-analysis/","text":"Static Code Analysis \u00b6 We use the following static code analysis tools: golangci-lint for compile time linting This is run on each pull request.","title":"Static Code Analysis"},{"location":"developers/static-code-analysis/#static-code-analysis","text":"We use the following static code analysis tools: golangci-lint for compile time linting This is run on each pull request.","title":"Static Code Analysis"},{"location":"users/cli/","text":"CLI \u00b6 The CLI allows to (amongst other things) manage projects, sync, watch, and list deployments, e.g.: WFNAME = ` argo-cloudops sync -n project1 -t target1 -p git_path -s git_sha ` argo-cloudops logs $WFNAME -f Reference \u00b6 You can find detailed reference here Help \u00b6 Most help topics are provided by built-in help: argo-cloudops --help","title":"CLI"},{"location":"users/cli/#cli","text":"The CLI allows to (amongst other things) manage projects, sync, watch, and list deployments, e.g.: WFNAME = ` argo-cloudops sync -n project1 -t target1 -p git_path -s git_sha ` argo-cloudops logs $WFNAME -f","title":"CLI"},{"location":"users/cli/#reference","text":"You can find detailed reference here","title":"Reference"},{"location":"users/cli/#help","text":"Most help topics are provided by built-in help: argo-cloudops --help","title":"Help"},{"location":"users/coreconcepts/","text":"Core Concepts \u00b6 This page serves as additional information in addition to the Cello Architecture . Project \u00b6 A project is a logical collection of all deployment targets. Properties \u00b6 Name Description name name for the project repository link to the github repository with all project manifests . Should match the auth method being used (HTTPS, SSH). Target \u00b6 A target represents a unique deployment for a project. It contains information related to cloud account access mechanism & policies for scoping permissions. Currently the only type of cloud account supported is AWS. Properties \u00b6 Name Description credential_type the type of credential mechanism to use. Currently only \"assumed_role\" role_arn the role that the service assumes policy_arns A list of AWS policy ARNs to use for permissions scope limiting policy_document An inline document to scope down permissions","title":"Core Concepts"},{"location":"users/coreconcepts/#core-concepts","text":"This page serves as additional information in addition to the Cello Architecture .","title":"Core Concepts"},{"location":"users/coreconcepts/#project","text":"A project is a logical collection of all deployment targets.","title":"Project"},{"location":"users/coreconcepts/#properties","text":"Name Description name name for the project repository link to the github repository with all project manifests . Should match the auth method being used (HTTPS, SSH).","title":"Properties"},{"location":"users/coreconcepts/#target","text":"A target represents a unique deployment for a project. It contains information related to cloud account access mechanism & policies for scoping permissions. Currently the only type of cloud account supported is AWS.","title":"Target"},{"location":"users/coreconcepts/#properties_1","text":"Name Description credential_type the type of credential mechanism to use. Currently only \"assumed_role\" role_arn the role that the service assumes policy_arns A list of AWS policy ARNs to use for permissions scope limiting policy_document An inline document to scope down permissions","title":"Properties"},{"location":"users/envvars/","text":"Environment Variables \u00b6 Cello uses a number of environment variables for configuration. In addition to the table below, you can review the start_local.sh script for examples. Name Description ARGO_CLOUDOPS_ADMIN_SECRET Secret for the Cello API VAULT_ROLE Role for accessing Vault API VAULT_SECRET Secret for access Vault instance VAULT_ADDR Endpoint for the Vault instance ARGO_ADDR Argo Endpoint ARGO_CLOUDOPS_WORKFLOW_EXECUTION_NAMESPACE Namespace to use to execute the deployments in Argo Workflows (Default: argo) ARGO_CLOUDOPS_CONFIG File that contains argo cloudops command configuration. Example SSH_PEM_FILE PEM file to use for GITHUB access authentication ARGO_CLOUDOPS_GIT_AUTH_METHOD A value of SSH or HTTPS depending on which authentication method prefered. ARGO_CLOUDOPS_GIT_HTTPS_USER User name for GITHUB access authentication via HTTPS. ARGO_CLOUDOPS_GIT_HTTPS_PASS Password for GITHUB access authentication via HTTPS. ARGO_CLOUDOPS_DB_HOST Database Host ARGO_CLOUDOPS_DB_USER Database User ARGO_CLOUDOPS_DB_PASSWORD Database Password ARGO_CLOUDOPS_DB_NAME Database name ARGO_CLOUDOPS_LOG_LEVEL The configured log level for Cello service (Default: Info) ARGO_CLOUDOPS_PORT Port which the Cello service listens (Default: 8443) ARGO_CLOUDOPS_IMAGE_URIS List of approved image URI patterns. See IsApprovedImageURI validation doc for examples","title":"Environment Variables"},{"location":"users/envvars/#environment-variables","text":"Cello uses a number of environment variables for configuration. In addition to the table below, you can review the start_local.sh script for examples. Name Description ARGO_CLOUDOPS_ADMIN_SECRET Secret for the Cello API VAULT_ROLE Role for accessing Vault API VAULT_SECRET Secret for access Vault instance VAULT_ADDR Endpoint for the Vault instance ARGO_ADDR Argo Endpoint ARGO_CLOUDOPS_WORKFLOW_EXECUTION_NAMESPACE Namespace to use to execute the deployments in Argo Workflows (Default: argo) ARGO_CLOUDOPS_CONFIG File that contains argo cloudops command configuration. Example SSH_PEM_FILE PEM file to use for GITHUB access authentication ARGO_CLOUDOPS_GIT_AUTH_METHOD A value of SSH or HTTPS depending on which authentication method prefered. ARGO_CLOUDOPS_GIT_HTTPS_USER User name for GITHUB access authentication via HTTPS. ARGO_CLOUDOPS_GIT_HTTPS_PASS Password for GITHUB access authentication via HTTPS. ARGO_CLOUDOPS_DB_HOST Database Host ARGO_CLOUDOPS_DB_USER Database User ARGO_CLOUDOPS_DB_PASSWORD Database Password ARGO_CLOUDOPS_DB_NAME Database name ARGO_CLOUDOPS_LOG_LEVEL The configured log level for Cello service (Default: Info) ARGO_CLOUDOPS_PORT Port which the Cello service listens (Default: 8443) ARGO_CLOUDOPS_IMAGE_URIS List of approved image URI patterns. See IsApprovedImageURI validation doc for examples","title":"Environment Variables"}]}